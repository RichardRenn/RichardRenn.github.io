[{"title":"GitHub教程 - Git安装配置","url":"/Git-Configuration.html","content":"环境变量vim ~/.bashrc\n\n\n在后面添加以下内容,以解决某些包(如perl、git)安装时的warning\n\nexport LC_ALL=&quot;C&quot;export LANGUAGE=&quot;zh_CN:zh&quot;\n\n当然也可以直接在命令终端中export临时设置环境变量\n安装apt-get install git # 这是Ubuntu下的命令yum install git # 这是CentOS下的命令brew install git # 这是MAC下的命令\n\n生成ssh密钥对ssh-keygen -t rsa -b 4096 -C &quot;your_email@example.com&quot;\n如果不想设置密码的话直接三次回车即可，和git生成密钥的命令相同。\n\n生成的密钥对位置在 ~&#x2F;.ssh，查看下公钥，后面要用到。\n\ncat ~/.ssh/id_rsa.pub\n\n\n内容类似下面这样\n\nssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAACAQC+am2s/r1n+xsipi/4H2ll8p3McdhQCLBwJGNbkaxpeWKtdbiUbqAWjHS436eNt/OF13VsyWLs5lb6J2I3J6GlCcEGMGOFc4gzLTP9e/TmXeyFlBMZkuSJTbsXvL9Q/tff/8Tgt4aVwR3OWlwfvPdtoyR0tGhDDQn8a0gzs04mPyMWjK6akt/zGCQ70Eo6stVMGCyMAL/PrHwdZ/puXjtw0T9HSs/ON/Jub+h3oKfgJVhpJNbIDR2r08LoEA0roTplI4aSR+JgnSKsXhIvTAUm+VRmWgz3oPYcNkaGkvBvA1gfk/baB6qxv0hkjPwtY5GIRkCU6cIcjG3U1LR6pnH+8Z0RbN9YaFFNRRf4rMnZ3n0jhYXCq7dzBoofLWRVlAqTlybF7xz9JNVQxiC+o5skBHJ/Eb7Ggtejc6TVW+FJaNUy5+yWqfhq57kC4zq+5HhAY9ToKZpYLKjJa7oG0eHAeOAgSd2jdDEvALegap4nrMHVLP8sOQlNFBMPjy1r0cW/Afp32gCtPOpQRuIkQdOnWUkzjObGTLaVffanhYnX470UNsvgQ+IyikhS5tiKPqkT317v6yFV4doeZgfNYtcgpLVZcVxkItTLS1h75d4h4MD2JVRk2nBGSLp5j2WIji4Tiy++LblV1Y5Y2wRcfefdXCIMT3jMNAcyhuCaNfaD/Q== your_email@example.com\n\n公钥添加到GitHub&gt;&gt;传送门 - 添加你自己的公钥&lt;&lt;\n\n将上一步的公钥拷贝下来，粘贴至GitHub网页以下位置\n\n\n配置用户名和邮箱git config --global user.name &quot;your_name&quot;git config --global user.email &quot;your_email@example.com&quot;\n\n克隆代码git clone git@github.com:user_name/project_name.git /path/to/your/sourcecode\n","categories":["GitHub教程"],"tags":["Git","GitHub"]},{"title":"GitHub教程 - 分支工作流程","url":"/GitHub-Branch-Workflow.html","content":"更新代码\n进入代码目录，更新代码\n\ncd ~/workspace/sourcecode/richardrenn/slarkgit pull origin master*git pull upstream master\n\n\n*查看所有远端库情况\n\ngit remote -v\n\norigin        git@github.com:RichardRenn/slark.git (fetch)origin        git@github.com:RichardRenn/slark.git (push)upstream        git@github.com:southflower/slark.git (fetch)upstream        git@github.com:southflower/slark.git (push)\n\n\n*查看所有分支情况，可看到当前的分支是origin&#x2F;master\n\ngit branch -a\n\n* master  remotes/origin/HEAD -&gt; origin/master  remotes/origin/master  remotes/origin/release  remotes/upstream/master  remotes/upstream/release\n\n新建分支\n本地新建分支，并切换到新建的分支\n\ngit checkout -b dev\n\n推送分支\n推送新分支到远端库和上游库，冒号前的是本地分支名，冒号后的是远程分支名\n\ngit push origin dev:devgit push upstream dev:dev\n\n\n此时再敲git branch -a 就可以看到已经在远端库和上游库都建好了分支\n\n* dev  master  remotes/origin/HEAD -&gt; origin/master  remotes/origin/dev  remotes/origin/master  remotes/origin/release  remotes/upstream/dev  remotes/upstream/master  remotes/upstream/release\n\n提交修改\n在本地的dev分支修改文件并提交推送到远端库\n\ngit add [file]git commit -m &quot;something&quot;git push origin dev*git push upstream dev   # 这一步直接推送到上游库的dev分支，可以省一次PR\n\n提交PR\n在网页通过PR的方式将dev代码推送到上游库的dev分支\n\n分支合入\n等dev调试稳定后再通过PR的方式将上游库的dev分支merge到其master分支，即可上线\n\n\n\nPR操作可以参考&gt;&gt;传送门 - Pull Request 工作流程&lt;&lt;\n\n","categories":["GitHub教程"],"tags":["Git","GitHub"]},{"title":"GitHub - 存储大文件","url":"/GitHub-Large-File-Storage.html","content":"问题的产生\n我在GitHub上有一个仓库用来存放收集到的各种技术类书籍的电子版，但是众所周知GitHub默认情况下是不支持存储超过100M的单个文件的（其实超过50M时就会有Warning）。当我push比较大的PDF版的书籍（比如JavaScript-DOM编程艺术-中文第2版.pdf）时就会抛Error：\n\nremote: error: File xxx is 109.19 MB; this exceeds GitHub&#x27;s file size limit of 100.00 MB\n\n\n\n下面是使用Git大文件存储扩展LFS来使GitHub支持大文件的版本管理的步骤：\n\n安装lfsgit lfs install\n\n添加想要被托管的大文件\n也可以直接添加一类文件，比如我的PDF文件\n\ngit lfs track &quot;*.pdf&quot;\n\n\n同时把仓库根目录下的.gitattributes也加入到git管理下\n\ngit add .gitattributes\n\n正常提交\n和正常的git提交命令一样\n\ngit add file.pdfgit commit -m &quot;Add new JS book&quot;git push origin master\n\n\n\n以上就是全部的步骤，下面是福利~\n\n\n福利 - 书架\n&gt;&gt;传送门 - 我的书架&lt;&lt;有需要的同学可以下载下来，哦，最好是挑对自己有用书籍下载单个文件，因为整个仓库可能会有几十个G。\n\n","categories":["GitHub教程"],"tags":["Git","GitHub"]},{"title":"GitHub教程 - Pull Request 工作流程","url":"/GitHub-Pull-Request-Workflow.html","content":"Fork仓库\n先在github上将源仓库fork到自己的仓库\n\n源仓库：git@github.com:southflower/slark.gitfork后：git@github.com:RichardRenn/slark.git\n\n检出代码\n在本地检出fork后的仓库代码\n\ncd ~/workspace/sourcecode/richardrenngit clone git@github.com:RichardRenn/slark.git ./slark\n\n关联上游源仓库\n进入代码目录，加入上游源仓库关联\n\ncd ./slarkgit remote add upstream git@github.com:southflower/slark.git\n\n更新代码\n更新源仓库代码到本地仓库\n\ngit fetch upstreamgit merge upstream/master\n\n提交代码\n在本地仓库中，修改代码后提交到自己的远端仓库\n\ngit add .git commit -m &quot;anything&quot;git push origin master\n\n提交PR\n在github网页上提交PR在自己的仓库界面点击”New Pull Request”\n\n\nPR合入\n然后待源仓库的作者将你的PR合入即可\n\n\n\n带分支的工作方式可以参考&gt;&gt;传送门 - 分支工作流程&lt;&lt;\n\n","categories":["GitHub教程"],"tags":["Git","GitHub"]},{"title":"Python - Celery - 调用任务","url":"/Python-Celery-Calling-Tasks.html","content":"前提\n有3个任务：add作加法运算, mul作乘法运算, xsum为求和运算\n\n@app.task(bind=True, base=BaseTask)def add(self, a, b):    return a + b@app.task(bind=True, base=BaseTask)def mul(self, a, b):    return a * b@app.task(bind=True, base=BaseTask)def xsum(self, *args):    return sum(args)\n\n立即执行任务add.apply_async()\n\n\n或者简写为：\n\nadd.delay()\n\n延时任务\n使用countdown参数使任务在60秒后执行：\n\nadd.apply_async(countdown=60)\n\n定时任务\n使用eta参数使任务在晚上9点整执行：\n\nimport datetimeexec_at = datetime.datetime(2019, 7, 28, 21, 0, 0, 0)add.apply_async(eta=exec_at)\n\n任务分组\n使用group生成一组任务并发执行\n\ntasks = group(add.si(x,x) for x in range(10))tasks.apply_async()# get方法可获取任务的返回值:res = tasks()res.get(timeout=1)  # [0, 2, 4, 6, 8, 10, 12, 14, 16, 18]\n\n任务分块\n使用chord将1000个任务分成100个一块，共10组\n\ntasks = add.chunks(((x, x) for x in range(1000)), 100).group()  # 转化为group# 每间隔60秒执行一组tasks.skew(step=60)tasks.apply_async()# 注意使用了skew后eta参数会失效，想要定时效果可以转化为countdown如：task.apply_async(countdown=(exec_at - now()).seconds)\n\n链式顺序执行\n任务签名signature：subtask&#x3D;signature，可以简写为s，如add.s()，当需要对任务做一定处理后执行时使用。s和si的区别：s相当于signature()，而si相当于signature(immutable&#x3D;True)。 s会把上个任务的结果传给下个任务，而si不传递结果。\n\n\n使用chain按顺序执行一队任务：\n\n# 前一个任务的结果作为后一个任务的第一个参数chain(add.s(1,1), add.s(2), add.s(3))()   # 不传递结果，仅仅按顺序执行chain(add.si(1,1), add.si(2,2), add.si(3,3))()# 也可以使用 | 链接任务，效果是一样的，如:all_task = (add.s(1,1) | add.s(2) | add.s(3))all_task = (add.si(1,1) | add.si(2，2) | add.si(3，2))all_task.delay()# chain还支持部分传参，如：c = (add.s(2) | mul.s(8))res = c(1)  # (1+2)*8res.get()  # 24# 搭配列表生成式实现更灵活,如task_list = [add.si(x,x) for x in range(3)]chain(*task_list)()  # 不要忘了加上最后的括号才可执行任务\n\n\n另一种调用方法:\n\nc =   (add.s(4, 16) | mul.s(2) | (add.s(4) | mul.s(8))) # ((4 + 16) * 2 + 4) * 8res = c.apply_async()  # 或者直接c()res.get()  # .get()方法可以获取链式任务的最终返回值352\n\n\n任务分割\n使用chord将任务分为header和body两部分，header任务执行完再执行body,其中header的返回结果会作为参数传递给body，如：\n\nres = chord(header=[add.s(1,2),mul.s(3,4)],body=add.s())()  # 任务(1+2)+(3*4)res.get()  # \n\n\n当一个group和另一个task组成chain时，会自动升级转化为chord，如：\n\nc = (group(add.s(i, i) for i in range(10)) | xsum.s())  # (0+0)+(1+1)+(2+2)+...+(9+9)res = c()res.get()  # 90\n","categories":["Python"],"tags":["Python","Celery","调用任务"]},{"title":"Linux开机启动项目录rc.d","url":"/Linux-Msconfig.html","content":"本文以&#x2F;init.d&#x2F;redis-server-2脚本为例，介绍如何自定义开机启动项。\n\n&#x2F;etc&#x2F;init.d目录下是所有的启动脚本，我们可以通过以下命令来运行。\n\n/etc/init.d/脚本名 参数\n\n查看当前启动级别Runlevel\n\n\n显示   N  2则当前的级别是2级,那么所有开机启动项就是在&#x2F;etc&#x2F;rc2.d目录下。\n\n查看原redis启动序号ls -l /etc/rc2.d\n\n\n这个目录下都是软链接（符号链接），链接到&#x2F;etc&#x2F;init.d目录。显示格式如下：S&#x2F;K + 序号 + 脚本名\n\nlrwxrwxrwx 1 root root  22 Dec  2 15:37 S20redis-server -&gt; ../init.d/redis-serverlrwxrwxrwx 1 root root  18 Aug 24  2017 S99rc.local -&gt; ../init.d/rc.local\n\n\n启动序号是20S开头是开机时的脚本启动顺序，按序号从小到大启动。K开头表示是关机时的脚本关闭顺序，按序号从大到小关闭。\n\n将启动脚本软链接到开机启动目录下ln -s /etc/init.d/redis-server-2 /etc/rc2.d/S20redis-server-2\n\n\n注意：如果两个redis有主从关系的话即需要有先后启动顺序，就需要适当的增大序号，如21\n\nln -s /etc/init.d/redis-server-2 /etc/rc2.d/S21redis-server-2\n\n\n*也可以使用update-rc.d命令，效果相同：\n\nupdate-rc.d -f redis-server-2 defaults 20\n\n取消开机启动\n方法一：使用update-rc.d命令\n\nupdate-rc.d -f redis-server-slark remove\n\n\n方法二：直接删除软链接\n\nrm -f /etc/rc2.d/S20redis-server-slark\n\n关于rc.local\nrc.local也是开机启动脚本，从ls -l &#x2F;etc&#x2F;rc2.d 命令的输出结果也可以看出，它的启动序号是99。所以rc.local里的内容是在所有更高级别的初始化脚本(rc1.d rc2.d …)运行之后再执行的。\n\n","categories":["Linux"],"tags":["Linux"]},{"title":"Python - 闭包","url":"/Python-Closure.html","content":"闭包的概念\n闭包(closure):内部函数中对enclosing作用域中的变量进行引用，这个内部函数就称为闭包。\n\n\n关于enclosing作用域相关的知识可以参考&gt;&gt;传送门 - Python函数作用域&lt;&lt;。\n\n举例解释\n首先要理解python中的函数也是一个对象，它是有属性和返回值的，而在函数执行完后其内部变量会被解释器回收。\n\n# Gpass_line = 60def func(score):    # E    print(&quot;%x&quot; % id(score)) # 以16进制打印score的id值    pass_line = 90    result = &quot;yes&quot; if score &gt;= pass_line else &quot;no&quot;    print(result)    def inner_func():  # score在E作用域中，inner_func就是个闭包, 有__closure__属性        # L        print(score)    print(inner_func.__closure__)    return inner_funcf = func(80) # 语句1 func()返回了一个函数对象inner_funcf() # 语句2 此时f即inner_funcprint(f.__closure__)\n\n运行结果：6e7e6ac0no(&lt;cell at 0x000001FC0B9AB6A8: int object at 0x000000006E7E6AC0&gt;,)80(&lt;cell at 0x0000019CDFBDB6A8: int object at 0x000000006E7E6AC0&gt;,)\n\n\n两个本来语句1运行完之后，func内部的变量都已经被回收了，那么这个 80为什么还可以被语句2打印出来呢？注意下这个现象f.__closure__这个元组的第一个元素的id和score变量的id值相同。说明如果内部函数中对enclosing作用域中的变量进行引用之后，这个变量就会被添加到inner_func的__closure__属性这个元组中，这样因为有了这个添加到元组的引用，score变量就不会被回收了，再调用f函数时，就会在它的__closure__属性中查找score变量，这样就自然而然的可以引用了。\n\n理解了这个例子就可以搞懂Python的闭包了。\n\n一个简单的应用\n下面的代码就是应用闭包达到了自定pass_line的目的\n\ndef func(pass_line):    def inner_func(score):  # score在E作用域中，inner_func就是个闭包, 有__closure__属性        result = &quot;yes&quot; if score &gt;= pass_line else &quot;no&quot;  # 此时引用了enclosing作用域中的pass_line，那么pass_line变量就被添加到了__closure__属性中        print(result)    return inner_funcf = func(90)  # 语句1 func()返回了一个函数对象inner_funcf(80)  # 语句2 此时f即inner_funcf2 = func(60)f2(80)\n\n运行结果：noyes\n\n经典错误代码\n参考&gt;&gt;传送门 - 闭包经典错误代码&lt;&lt;\n\ndef foo():    a = 1    def bar():        a = a + 1        return a    return barc = foo()c()\n\n会报错如下：local variable &#x27;a&#x27; referenced before assignment \n\n\n这是因为在执行代码 c &#x3D; foo()时，python会导入全部的闭包函数体bar()来分析其的局部变量，python规则指定所有在赋值语句左面的变量都是局部变量，则在闭包bar()中，变量a在赋值符号”&#x3D;”的左面，被python认为是bar()中的局部变量。再接下来执行print c()时，程序运行至a &#x3D; a + 1时，因为先前已经把a归为bar()中的局部变量，所以python会在bar()中去找在赋值语句右面的a的值，结果找不到，就会报错。解决的方法很简单:\n\ndef foo():    a = [1]    def bar():        a[0] = a[0] + 1        return a[0]    return bar\n\n\n只要将a设定为一个容器就可以了。这样使用起来多少有点不爽，所以在python3以后，在a &#x3D; a + 1 之前，使用语句nonloacal a就可以了，该语句显式的指定a不是闭包的局部变量。\n\n","categories":["Python"],"tags":["Python","闭包"]},{"title":"Python - 浅拷贝和深拷贝解析","url":"/Python-Copy-Deepcopy.html","content":"浅拷贝和深拷贝的区别\n浅拷贝(copy)：仅拷贝对象，但不拷贝此对象内的子对象。深拷贝(deepcopy)：完全拷贝对象，包括其内部的子对象。\n\n举例理解# -*- coding:utf-8 -*-import copya = &#123;0:1, 1:[1,2]&#125;a1 = copy.copy(a)  # 浅拷贝a2 = copy.deepcopy(a)  # 深拷贝a[1].append(3)print(a, &#x27;%x&#x27; % id(a), &#x27;%x&#x27; % id(a[1]))  # 使用16进制格式化输出id值print(a1, &#x27;%x&#x27; % id(a1), &#x27;%x&#x27; % id(a1[1]))print(a2, &#x27;%x&#x27; % id(a2), &#x27;%x&#x27; % id(a2[1]))\n\n输出结果：&#123;0: 1, 1: [1, 2, 3]&#125; 220a8caf2d0 220aa969e08&#123;0: 1, 1: [1, 2, 3]&#125; 220a8caf318 220aa969e08&#123;0: 1, 1: [1, 2]&#125; 220aa937c18 220aa969ec8\n\n\n从输出结果进行分析：1.a、a1、a2三者的id值不同。说明不论深浅拷贝都能得到新的对象。2.a1[1]和a[1]的id值相同，a2[1]和a[1]的id值不同。说明浅拷贝不能拷贝子对象，执行浅拷贝得到的对象a1的子对象和原对象a的子对象使用的是相同的一块内存，但是执行深拷贝得到的对象a2却和原对象a完全独立。这也是为什么当a[1].append(3)后，a1[1]也跟着变了，而a2[1]却没变。\n\n\na.copy()和copy.copy(a)的区别\n虽然两者都是浅拷贝，但是copy.copy()能够拷贝的对象更多，即某些对象本身是没有copy属性的，比如元组(tuple)。如果将上例中的a值替换为a &#x3D; (1, [1,2])，那么执行a1 &#x3D; a.copy()时是会报错的：\n\n# -*- coding:utf-8 -*-a = (1, [1,2])a1 = a.copy()\n\nAttributeError: &#x27;tuple&#x27; object has no attribute &#x27;copy&#x27;\n\n引申: 手写字典深拷贝def deep_copy(x):    &#x27;&#x27;&#x27;仅适用于子对象是字典的情况&#x27;&#x27;&#x27;    x1 = &#123;&#125;    for k, v in x.items():        if isinstance(v, dict):  # 当子对象是字典类型时递归执行            x1[k] = deep_copy(v)        else:            x1[k] = v    return x1\n\n\n如果子对象是数组或者元组的话，只要在赋值前价格数据类型判断，然后根据不同的类型赋值给不同的变量即可兼容。\n\n","categories":["Python"],"tags":["Python","浅拷贝和深拷贝"]},{"title":"Python - 装饰器","url":"/Python-Decorator.html","content":"装饰器的概念\n装饰器(decorator):装饰器是一种闭包的使用，要理解装饰器的原理必须先理解python闭包的概念。\n\n\n关于闭包的知识可以参考&gt;&gt;传送门 - Python闭包&lt;&lt;。\n\n举例理解# -*- coding: utf-8 -*-def deco(func):    print(&quot;deco&quot;)    def inner_deco(*args):  # 调用的enclosing作用域中的对象，inner_deco函数就是个闭包        print(&quot;inner_deco&quot;)        for a in args:            if not isinstance(a, int): # 参数检查语句                return 0        return func(*args)  # 调用了enclosing作用域的func，所以func会被加入到inner_deco的__closure__属性中    return inner_deco@deco  # 语法糖，就相当于func_sum = deco(func_sum)，此时func_sum就指向了inner_deco。可以理解为func_sum被deco装饰后变成了inner_decodef func_sum(*args):    print(&quot;func_sum&quot;)    return sum(args)@decodef func_min(*args):    print(&quot;func_min&quot;)    return min(args)# func_sum = deco(func_sum)print(func_sum(1,2,&#x27;3&#x27;))print(func_min(4,5,6))\n\n运行结果：decodecoinner_deco0inner_decofunc_min4\n\n\n@deco只是一种语法糖写法之所以打印结果中没有输出：”func_sum”，是因为在执行参数检查语句时return 0了。\n\n知识点装饰器在何时生效？\n在main函数之前，import时就生效了。因为@deco就相当于func_sum &#x3D; deco(func_sum)，是写在最外面的。如果把上述例子中最后的两个print语句注释掉的话，执行结果将会是：\n\ndecodeco\n\n装饰器能不能返回别的函数？\n当然可以，这样就可以修改函数的功能了。即被装饰的函数的功能取决于inner_deco返回的是哪个函数。\n\n","categories":["Python"],"tags":["Python","装饰器"]},{"title":"PostgreSQL - 经纬度计算距离ACOS函数ERROR: input is out of range","url":"/PostgreSQL-Lng-Lat-ACOS-ERROR-Input-Is-Out-Of-Range.html","content":"问题背景\n项目中需要计算两个点的距离，已记录对应的经纬度计算公式如下:\n\nSELECT ROUND((6371393.0*ACOS(SIN(点1纬度/180*PI())*SIN(点2纬度/180*PI())+COS(点1纬度/180*PI())*COS(点2纬度/180*PI())*COS((点1经度-点2经度)/180*PI())))::NUMERIC, 3);\n\n问题复现\n点1位置:  经度122.132181、纬度40.272723，点2位置与点1相同，正常结果距离应该是0，实际执行结果如下\n\nSELECT ROUND((6371393.0*ACOS(SIN(40.272723/180*PI())*SIN(40.272723/180*PI())+COS(40.272723/180*PI())*COS(40.272723/180*PI())*COS((122.132181-122.132181)/180*PI())))::NUMERIC, 3);\n\n报错: \n\nERROR:  input is out of range\n\n问题定位\n反余弦ACOS函数的参数范围必须在[-1,1]范围内，当参数超出范围时就会报错\n\n-- 验证ACOS(1)的值dev=# SELECT ACOS(1); acos------    0(1 row)-- 查询ACOS的入参, 输出为1dev=# SELECT SIN(40.272723/180*PI())*SIN(40.272723/180*PI())+COS(40.272723/180*PI())*COS(40.272723/180*PI())*COS((122.132181-122.132181)/180*PI()); ?column?----------        1(1 row)-- 比较输出值与1的大小， 输出值竟然比1大！dev=# SELECT SIN(40.272723/180*PI())*SIN(40.272723/180*PI())+COS(40.272723/180*PI())*COS(40.272723/180*PI())*COS((122.132181-122.132181)/180*PI()) &gt; 1; ?column?---------- t(1 row)\n\n原因描述\n二进制无法精确表示浮点数计算后的值，当计算后的值理论上为1时，在计算机中存储的可能是1.0000000000000001或者0.999999999999999在PG的低版本中(上面测试用的版本是10.20)无法直观的看出精度，只能通过比较的方式得到结论在PG较高的版本中(如12版本)可以直观的看出结果, 存储的值是1.0000000000000002\n\ndev=# SELECT SIN(40.272723/180*PI())*SIN(40.272723/180*PI())+COS(40.272723/180*PI())*COS(40.272723/180*PI())*COS((122.132181-122.132181)/180*PI());      ?column?-------------------- 1.0000000000000002(1 row)\n\n解决方案\nPG有一对函数可计算最大值和最小值: GREATEST取最大值，LEAST取最小值\n\ndev=# SELECT GREATEST(1,2,3,4), LEAST(1,2,3,4); greatest | least----------+-------        4 |     1(1 row)\n\nGREATES和 LEAST函数搭配使用可以限制ACOS函数的参数只能在[-1,1]之间\n\n-- 当在[-1,1]范围内时取真实值dev=# SELECT GREATEST(LEAST(0.99, 1), -1); greatest----------     0.99(1 row)-- 当超出[-1,1]范围内时取边界值dev=# SELECT GREATEST(LEAST(1.01, 1), -1); greatest----------        1(1 row)-- 修改后可正常执行的SQL如下:dev=# SELECT ACOS(GREATEST(LEAST(SIN(40.272723/180*PI())*SIN(40.272723/180*PI())+COS(40.272723/180*PI())*COS(40.272723/180*PI())*COS((122.132181-122.132181)/180*PI()), 1), -1)); acos------    0(1 row)\n\n更健壮的根据经纬度计算距离的SQL语句SELECT ROUND((6371393.0*ACOS(GREATEST(LEAST(SIN(点1纬度/180*PI())*SIN(点2纬度/180*PI())+COS(点1纬度/180*PI())*COS(点2纬度/180*PI())*COS((点1经度-点2经度)/180*PI()), 1), -1)))::NUMERIC, 3);\n","categories":["PostgreSQL"],"tags":["PostgreSQL","PG","ACOS","经纬度"]},{"title":"Python - 数组切片、更新、排序","url":"/Python-List-Slice.html","content":"数组切片l = [1, 2, 3, 4, 5, 6, 7, 8, 9]l[:]  # 所有元素 # [1, 2, 3, 4, 5, 6, 7, 8, 9]l[0]  # 第一个元素# 1l[1:3]  # 第2~4个元素，不包括第4个# [2, 3]l[3:]  # 第4~最后一个元素# [4, 5, 6, 7, 8, 9]l[:3]  # 第1~4个元素，不包括第4个# [1, 2, 3]l[:-1]  # 第1~最后一个元素，不包括最后一个# [1, 2, 3, 4, 5, 6, 7, 8]l[2:-1:2]  # 从第3~最后一个元素中每隔2个步长取一个，不包括最后一个元素# [3, 5, 7]l[::3]  # 每隔3个步长取一个元素# [1, 4, 7]\n\n数组更新l = [1, 2, 3, 4, 5, 6, 7, 8, 9]l.append(0)  # 列表最后追加一个元素0# [1, 2, 3, 4, 5, 6, 7, 8, 9, 0]l.extend([0, 0])  # 列表后面追加另一个列表# [1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 0]l.insert(1, &#x27;0&#x27;)  # 在第1个元素的位置插入字符串&#x27;0&#x27;# [1, &#x27;0&#x27;, 2, 3, 4, 5, 6, 7, 8, 9]l[1:3] = [0]  # 用0替换第2~4个元素，不包括第4个# [1, 0, 4, 5, 6, 7, 8, 9]l[-2:] = [0, 0, 0, 0]  # 将最后两个元素替换为四个0# [1, 2, 3, 4, 5, 6, 7, 0, 0, 0, 0]l.pop()  # 弹出最后一个元素,返回该元素的值# [1, 2, 3, 4, 5, 6, 7, 8]l.pop(0)  # 弹出第一个元素，返回该元素的值# [2, 3, 4, 5, 6, 7, 8, 9]del l[0]  # 删除第一个元素# [2, 3, 4, 5, 6, 7, 8, 9]\n\n数组排序l = [1, 2, 3, 4, 5, 6, 7, 8, -9]l.reverse()  # l反向# [-9, 8, 7, 6, 5, 4, 3, 2, 1]list(reversed(l))  # l反向,与l.reverse()的区别：后者直接作用于l，返回None，前者返回一个迭代器l.sort()  # 对l进行排序, 默认从小到大，升序# [-9, 1, 2, 3, 4, 5, 6, 7, 8]sorted(l)  # 升序排序，与l.sort()的区别：后者直接作用于l，返回None，前者返回一个新的列表# [-9, 1, 2, 3, 4, 5, 6, 7, 8]l.sort(reverse=True)  # 对l进行从大到小排序，降序，可与key参数搭配灵活使用# [8, 7, 6, 5, 4, 3, 2, 1, -9]l.sort(key=lambda x: abs(x))  # 按指定的方法进行排序，一般与lambda临时函数配合使用，也可以使用自定义方法如：def my_f(x):    return abs(x) # 取绝对值l.sort(key=my_f) # 按自定义方法进行排序l = [(1,2), (-4,3), (6,0)]l.sort(key=lambda x: x[1])  # 按子元组的第二个元素大小升序排列# [(6,0), (1,2), (-4,3)]l.sort(key=lambda x: abs(x[0]), reverse=True)  # 按第一个元素的绝对值大小降序排列# [(6,0), (-4,3), (1,2)]\n\n其他数组操作[1, 2] * 4  # [1,2]重复4次# [1, 2, 1, 2, 1, 2, 1, 2]l = [1, 2, 3, 4, 5, 6, 5, 8, 8]l.count(8)  # 统计8出现的次数# 2l.index(5)  # 找到5第一次出现的位置索引值(列表中没有5的话会报错ValueError)# 4\n","categories":["Python"],"tags":["Python","数组"]},{"title":"Python - 图片处理 - OpenCV图片与PIL.Image对象互相转化","url":"/Python-OpenCV-Image-PIL-Image.html","content":"起因\n因项目需要对视频封面图片作以下处理：宽高比不为一的图片处理成两端模糊填充的正方形，使得呈现如下效果:\n\n\n\n思路\n使用PIL库对图片作裁减和放大处理;\n上一步得到的图片转化到OpenCV图像做高斯模糊处理(因为PIL模块的图片模糊滤镜强度不够);\n上一步处理好的图片转化为PIL.Image,将原图居中合成进来;\n处理好的图片保存到本地或者转化为内存中的文件对象作其它操作: 上传下载等.\n\n代码实现\n涉及到的代码库 Pillow&#x3D;&#x3D;4.3.0, opencv-python&#x3D;&#x3D;4.1.0.25, numpy&#x3D;&#x3D;1.16.0\n\nimport requestsfrom io import BytesIOfrom PIL import Imageimport numpy as npimport cv2def crop_img_on_ratio(img, ratio):    &quot;&quot;&quot;按比例裁减图片&quot;&quot;&quot;    ratio_w, ratio_h = ratio    img_w, img_h = img.size    if img_h/img_w &gt;= ratio_h/ratio_w:        h = int(img_w*ratio_h/ratio_w)        box = (0, int((img_h-h)/2), img_w, int((img_h+h)/2))    else:        w = int(img_h*ratio_w/ratio_h)        box = (int((img_w-w)/2), 0, int((img_w+w)/2), img_h)    return img.crop(box)def mix_img_icon(img, icon):    &quot;&quot;&quot;图片图标合成，居中&quot;&quot;&quot;    img_w, img_h = img.size    icon_w, icon_h = icon.size    box = (int((img_w-icon_w)/2), int((img_h-icon_h)/2))    if icon.format == &#x27;PNG&#x27;:        img.paste(icon, box=box, mask=icon)    else:        img.paste(icon, box=box)def get_blur_image(img):    &quot;&quot;&quot;宽高比不为1的图片处理成两端模糊填充的正方形&quot;&quot;&quot;    w, h = img.size  # 获取图片宽高    a = max(w, h)  # 获取正方形边长    crop_img = crop_img_on_ratio(img, (1, 1))  # 裁减为正方形    scale_img = crop_img.resize((a, a), resample=Image.ANTIALIAS)  # 等比放大    cv_img = cv2.cvtColor(np.asarray(scale_img), cv2.COLOR_RGB2BGR)  # 转化为 opencv image    cv_gb_img = cv2.GaussianBlur(cv_img, (0, 0), 7)  # opencv 高斯模糊    gb_img = Image.fromarray(cv2.cvtColor(cv_gb_img, cv2.COLOR_BGR2RGB))  # 转化为PIL.Image    mix_img_icon(gb_img, img)  # 将原图合成进来    return gb_imgif __name__ == &quot;__main__&quot;:    # 从本地读取图片    source_img = Image.open(&#x27;/path/to/source_image.jpg&#x27;)    # 从url读取图片    source_img = Image.open(BytesIO(requests.get(&#x27;http://url/for/source_image.jpg&#x27;).content))        # 获取模糊后的图片    blur_img = get_blur_image(source_img)    # 图片保存到本地    gb_img.save(&#x27;/path/to/target_image.jpg&#x27;, &quot;JPEG&quot;)    # 图片保存为内存中的类文件对象    img_file = BytesIO()    image.save(img_file, &quot;JPEG&quot;)\n\n\n引申\nPIL模块可以对图片作很多滤镜操作达到不同效果:\n\nfrom PIL import ImageFiltertarget_img = source_img.filter(ImageFilter.BLUR)  # 模糊target_img = source_img.filter(ImageFilter.CONTOUR)  # 轮廓target_img = source_img.filter(ImageFilter.EDGE_ENHANCE)  # 边界加强target_img = source_img.filter(ImageFilter.EDGE_ENHANCE_MORE)  # 边界加强(阀值更大)target_img = source_img.filter(ImageFilter.EMBOSS)  # 模糊滤镜target_img = source_img.filter(ImageFilter.FIND_EDGES)  # 边界target_img = source_img.filter(ImageFilter.SMOOTH)  # 平滑target_img = source_img.filter(ImageFilter.SMOOTH_MORE)  # 平滑(阀值更大)target_img = source_img.filter(ImageFilter.SHARPEN)  # 锐化\n","categories":["Python"],"tags":["Python","OpenCV","Pillow","图片处理"]},{"title":"Python - 函数作用域","url":"/Python-Function-Scope.html","content":"函数作用域\nL：local 函数内部作用域；\nE：enclosing 函数内部与它的内嵌函数之间；\nG：global 全局作用域，在同一个.py文件最外层；\nB：build-in 解释器内置作用域。\n\n对象查找顺序\nL &gt; E &gt; G &gt; B\n\n举例解释# -*- conding: utf-8 -*-# Gpass_line = 60 def func(score):    # E    pass_line = 90     result = &quot;yes&quot; if score &gt;= pass_line else &quot;no&quot;    print(result)    def inner_func():        # L        # score = 81        print(score)    inner_func()    print(max(1,2))  # Bfunc(80)\n","categories":["Python"],"tags":["Python","函数作用域"]},{"title":"Python - OpenCV - 截取视频某个时间点的一帧","url":"/Python-OpenCV-Snapshot.html","content":"起因\n最近在做一个短视频类的小程序，需要从用户上传的视频中截取封面图。因为有些用户喜欢用“名不副实”的封面来吸引人点进去，所以拟截取视频播放1秒时的一帧图片作为封面。\n\n安装OpenCV库pip install opencv-python\n\n代码实现：截取1秒时的一帧import cv2video_path = &quot;/home/richard/oss_tmp/a.mp4&quot;cover_path = &quot;/home/richard/oss_tmp/a_cover.jpg&quot;try:    vc = cv2.VideoCapture(video_path)  # 读取视频    video_width = int(vc.get(cv2.CAP_PROP_FRAME_WIDTH))  # 视频宽度    video_height = int(vc.get(cv2.CAP_PROP_FRAME_HEIGHT))  # 视频高度    vc.set(cv2.CAP_PROP_POS_MSEC, 1000)  # 设置读取位置，1000毫秒    rval, frame = vc.read()  # 读取当前帧，rval用于判断读取是否成功    if rval:        cv2.imwrite(cover_path, frame)  # 将当前帧作为图片保存到 cover_path    else:        print(&quot;读取失败&quot;)except Exception as e:    print(f&quot;获取视频封面图失败: &#123;e&#125;&quot;)\n","categories":["Python"],"tags":["Python","OpenCV","视频截图"]},{"title":"Python - 如何使用PG的COPY命令将SQL结果直接输出到客户端文件","url":"/Python-Psycopg2-Copy-Odoo-OE.html","content":"背景\npsql中可以执行copy命令将数据导出到文件，有两种变体\n\nCOPY (SELECT id FROM table_name LIMIT 1) TO &#x27;/path/to/file.csv&#x27; WITH CSV DELIMITER &#x27;,&#x27;;\\COPY (SELECT id FROM table_name LIMIT 1) TO &#x27;/path/to/file.csv&#x27; WITH CSV DELIMITER &#x27;,&#x27;;\n\nCOPY和\\COPY的区别是前者输出的文件在服务端(且需要有服务端的管理员权限，如果是使用的云数据库则不可用)，后者输出到客户端。但如果使用COPY TO STDOUT的形式则可以将数据回传到客户端，可以用于文件写入，如\n\nCOPY (SELECT id FROM table_name LIMIT 1) TO STDOUT WITH CSV DELIMITER &#x27;,&#x27;;\n\n踩坑探索\n在python中使用psycopg2库连接PG直接执行COPY或者\\COPY语句都会报错\n\nimport psycopg2conn = psycopg2.connect(&quot;dbname=dbname user=user password=password&quot;)cursor = conn.cursor()# COPY写法sql = &quot;COPY (SELECT id FROM table_name LIMIT 1) TO &#x27;/path/to/file.csv&#x27; WITH CSV DELIMITER &#x27;,&#x27;&quot;  # 文件会输出到数据库服务器上sql = &quot;COPY (SELECT id FROM table_name LIMIT 1) TO STDOUT WITH CSV DELIMITER &#x27;,&#x27;&quot;  # STDOUT回传数据到客户端# \\COPY写法sql = &quot;\\COPY (SELECT id FROM table_name LIMIT 1) TO &#x27;/path/to/file.csv&#x27; WITH CSV DELIMITER &#x27;,&#x27;&quot;cursor.execute(sql)cursor.close()\n\n报错信息分别如下:\n\nProgrammingError: can&#x27;t execute COPY TO: use the copy_to() method instead\nSyntaxError: syntax error at or near &quot;\\&quot;LINE 1: \\COPY (SELECT id FROM table_name LIMIT 1...        ^\n\n\n查看psycopg2文档\n发现copy命令被封装成了copy_expert函数\n\ndef copy_expert(self, sql, file, size=8192): # real signature unknown; restored from __doc__    &quot;&quot;&quot;    copy_expert(sql, file, size=8192) -- Submit a user-composed COPY statement.    `file` must be an open, readable file for COPY FROM or an open, writable    file for COPY TO. The optional `size` argument, when specified for a COPY    FROM statement, will be passed to file&#x27;s read method to control the read    buffer size.    &quot;&quot;&quot;    passdef copy_from(self, file, table, sep=None, null=None, size=8192, columns=None): # real signature unknown; restored from __doc__    &quot;&quot;&quot; copy_from(file, table, sep=&#x27;\\t&#x27;, null=&#x27;\\\\N&#x27;, size=8192, columns=None) -- Copy table from file. &quot;&quot;&quot;    passdef copy_to(self, file, table, sep=None, null=None, columns=None): # real signature unknown; restored from __doc__    &quot;&quot;&quot; copy_to(file, table, sep=&#x27;\\t&#x27;, null=&#x27;\\\\N&#x27;, columns=None) -- Copy table to file. &quot;&quot;&quot;    passdef execute(self, query, vars=None): # real signature unknown; restored from __doc__    &quot;&quot;&quot; execute(query, vars=None) -- Execute query with bound vars. &quot;&quot;&quot;    pass\n\n使用psycopg2实现\n可以使用copy_expert函数将sql结果输出到客户端文件，代码如下\n\nimport psycopg2conn = psycopg2.connect(&quot;dbname=dbname user=user password=password&quot;)cursor = conn.cursor()sql = &quot;&quot;&quot;COPY (SELECT id FROM table_name LIMIT 1) TO STDOUT WITH CSV DELIMITER &#x27;,&#x27;&quot;&quot;&quot;with open(&#x27;/path/to/file.csv&#x27;, &#x27;w&#x27;) as f:    cursor.copy_expert(sql, f)cursor.close()\n\n引申：在Odoo中实现\n在Odoo(原OpenERP)中使用cr执行上述命令查看Odoo代码发现Odoo的cr.execute是将psycopg2库的execute封装了一层，但是使用_obj依然可以引用到原生的cusor\n\nclass ConnectionPool(object):    ...    def borrow(self, dsn):        self._debug(&#x27;Borrow connection to %r&#x27;, dsn)        try:            result = psycopg2.connect(dsn=dsn, connection_factory=PsycoConnection, connect_timeout=4)        except psycopg2.Error:            _logger.exception(&#x27;Connection to the database failed&#x27;)            raise        self._debug(&#x27;Create new connection&#x27;)        return resultclass Cursor(object):    ...    # lazy load connection, cursor    @property    def _cnx(self):        if self._cnx_cache is None:            self._cnx_cache = self._pool.borrow(dsn(self.dbname))        return self._cnx_cache    @property    def _obj(self):        if self._obj_cache is None:            self._obj_cache = self._cnx.cursor(cursor_factory=DictCursor)        return self._obj_cache    def execute(self, query, params=None, log_exceptions=None):        ...        try:            ...            res = self._obj.execute(query, params)        except psycopg2.ProgrammingError as pe:            ...        ...\n\n\n所以在Odoo中使用COPY命令导出的代码为:\n\nsql = &quot;&quot;&quot;COPY (SELECT id FROM table_name LIMIT 1) TO STDOUT WITH CSV DELIMITER &#x27;,&#x27;&quot;&quot;&quot;with open(&#x27;/path/to/file.csv&#x27;, &#x27;w&#x27;) as f:    cr._obj.copy_expert(sql, f)","categories":["Python"],"tags":["Python","PostgreSQL","PG","iPython","Odoo","OE","OpenERP"]},{"title":"Python - Super()继承顺序 - MRO顺序C3算法解析","url":"/Python-Super.html","content":"拓扑排序算法在解析MRO之前，需要先理解拓扑排序（Topological Sorting）算法\n\n在图论中，当有向无环图（Directed Acyclic Graph,简称DAG）的所有顶点组成一个线性序列，且该序列满足以下条件：1.每个顶点出现且只出现一次；2.若存在一条从顶点 A 到顶点 B 的路径，那么在序列中顶点 A 出现在顶点 B 的前面。则称该序列是此DAG的一个拓扑排序。\n\n那么这个序列是如何得到的呢？\n\n1.选择一个入度为0（即只有出边没有入边）的顶点并输出；2.删除此顶点及所有出边。循环执行上面两步直到不存在入度为0的顶点为止，顶点输出的顺序即为拓扑排序。\n\n用图比较容易理解：\n\n\n拓扑排序得到的序列为：5 → 4 → 2 → 3 → 1\n\n\n注意：在某些情况下拓扑排序可有多个结果\n\nMRO - C3算法的工作原理\nPython的Super()函数的方法解析顺序（Method Resolution Order, 简称MRO）使用的C3算法，可以理解为在拓扑排序算法的基础上考虑了基类出现的先后顺序。\n\n\nC3算法的本质就是Merge，Merge规则如下：取第一序列的第一元素，与所有后续序列除第一元素外的所有元素进行比较。若不存在相同者，则取出这个元素并从全部序列中删除；若存在，则跳过此序列，取下一序列的第一元素往后进行相同的比较，直到可以取出某个元素并从全部序列中删除。然后回到最前面的序列，取第一元素进行下一轮循环比较，直到取出所有元素。取出的元素组成的列表即为__mro__列表。\n\n\n之所以使用这个算法，是因为基于深度优先的搜索算法（见后文）不满足本地优先级和单调性的需求。本地优先级：指声明时父类的顺序，比如D(B,C)，则访问D类对象属性时，应该优先查找B，然后再查找C。单调性：如果在D的解析顺序中，B在C的前面，那么在D的所有子类里，也必须满足这个顺序。\n\n试看以下代码\nclass A(object):    passclass B(A):    passclass C(A):    passclass D(B, C):    passclass E(D, C):    pass\n\n假设X.mro &#x3D; L(X), +为merge，则C3算法的过程为：\n\nL(E) &#x3D; E + L(D) + L(C) + DCL(E) &#x3D; E + [D+L(B)+L(C)+BC] + [C+L(A)+A] + DCL(E) &#x3D; E + [D + [B+L(A)+A] + [C+L(A)+A] + BC] + [C+A+A] + DCL(E) &#x3D; E + [D + BA + CA + BC] + CA + DCL(E) &#x3D; E + DBCA + CA + DCL(E) &#x3D; EDBCA\n\n\n排序结果为：E → D → B → C → A → object\n\n到此为止，基本可以理解MRO的排序算法的运算过程了。\n\n如何直接查看某个类的继承顺序？每个类都有对应的__mro__属性和mro()方法：\nE.__mro__E.mro()\n\n(&lt;class &#x27;__main__.E&#x27;&gt;, &lt;class &#x27;__main__.D&#x27;&gt;, &lt;class &#x27;__main__.B&#x27;&gt;, &lt;class &#x27;__main__.C&#x27;&gt;, &lt;class &#x27;__main__.A&#x27;&gt;, &lt;class &#x27;object&#x27;&gt;)[&lt;class &#x27;__main__.E&#x27;&gt;, &lt;class &#x27;__main__.D&#x27;&gt;, &lt;class &#x27;__main__.B&#x27;&gt;, &lt;class &#x27;__main__.C&#x27;&gt;, &lt;class &#x27;__main__.A&#x27;&gt;, &lt;class &#x27;object&#x27;&gt;]\n\n什么是深度优先算法？\n这是Python2.3之前的版本所使用的搜索算法，也是所有Python2.x版本中默认的经典类的搜索算法。\n\n试看以下代码在2.2版本中的搜索结果：\nclass A():    def foo():        print(&quot;in A&quot;)class B(A):    # def foo():    #     print(&quot;in B&quot;)    passclass C(A):    def foo():        print(&quot;in C&quot;)class D(B, C):    passD().foo()\n\nin A\n\n\n按照深度优先的原则: D → B → A → C，当B或A中有foo()方法时，根本轮不到去找C类中的foo()方法！\n\n\n为了解决这个问题，在Python2.3版本引入了新式类（使用C3算法），但是必须显式的声明继承自object才能生效。\n\nclass A(object):    pass···\n\n\nPython3.x版本所有类默认为新式类，不必显式的声明。另：经典类中所有的特性都是可读可写的, 新式类中的特性只读的, 只能通过添加特性达到目的。\n\n\n引申：广度优先算法\n广度优先算法是优先查找距离最近的节点，即横向查找。则上面的代码排序结果为：D → B → C → A而使用第二部分的代码，排序结果为：E → D → C → B → A → object\n\n","categories":["Python"],"tags":["Python","Super()","继承顺序","MRO","C3算法"]},{"title":"Python - virtualenv虚拟环境配置","url":"/Python-Virtualenv.html","content":"安装pip install virtualenv\n\n创建虚拟环境git clone git@github.com:RichardRenn/happy.git /var/www/happy # 克隆项目代码cd /var/www/happy # 进入项目目录virtualenv venv # 创建虚拟环境目录./venv\n\n激活并进入虚拟环境source ./venv/bin/activate\n\n\n当看到命令行前面显示(venv)标志时即表示已进入虚拟环境\n\n安装依赖库\n同在普通环境下的安装命令是相同的，只不过所有的库都会被安装到虚拟环境目录下\n\npip install [module-name]\n\n\n*也可以从需求库依赖文件安装所需库\n\npip install -r requirements.txt\n\n\n需求库依赖文件可以从任何一个虚拟环境中导出，导出命令如下：\n\npip freeze &gt; requirements.txt\n\n\n推荐保持依赖文件为最新状态，并存放在项目代码目录下，可以很方便地在新机器上安装部署项目虚拟环境。\n\n退出虚拟环境deactivate\n","categories":["Python"],"tags":["Python","virtualenv"]},{"title":"Python - 配置iPython直接在命令行调试Odoo(openerp)代码","url":"/Python-iPython-Odoo-OE.html","content":"先看效果\n安装ipythonpip install ipython\n\n创建ipython配置文件ipython profile create apple\n\n*列出所有配置文件ipython profile list\n\n*查看配置文件位置ipython profile locate apple\n\n创建预加载OE配置文件vim ~/.ipython/profile_apple/startup/00-load-oe.py\n\n\n内容如下：\n\n#!/usr/bin/python# coding: utf-8# author: richardimport osimport sysimport configparserOE_CONF_PTH = &#x27;/path/to/app-server-local.conf&#x27;def abs_path(path):    if path.startswith(&#x27;~&#x27;):        return os.path.expanduser(path)    return pathif __name__ == &#x27;__main__&#x27;:    # 加载OE配置文件    conf = configparser.ConfigParser()    conf.read(abs_path(OE_CONF_PTH))    options = dict(conf.items(&#x27;options&#x27;))    db_name = options[&#x27;db_name&#x27;]    addons_path = abs_path(options[&#x27;addons_path&#x27;])    proj_path = addons_path.split(&#x27;/openerp/addons&#x27;)[0]    openerp_path = addons_path.split(&#x27;/addons&#x27;)[0]    # 加入系统路径    sys.path.extend([proj_path, openerp_path])    # OE解析配置    import openerp    openerp.tools.config.parse_config([&#x27;-c&#x27;,abs_path(OE_CONF_PTH)])    # 生成数据库cursor    uid = 1    db_conn = openerp.sql_db.db_connect(db_name)    cr = db_conn.cursor()    # 若要启用连接池，需将代码中所有import改为从openerp引入    # 如 from osv import fields 需改为 from openerp.osv import fields    pool = openerp.pooler.get_pool(db_name)    # 其他预导入的包和方法    import redis    import json    import datetime    from openerp.tools import gen_signature    redis_pool = openerp.redis_pool.redis_pool    redis_ins = redis.Redis(connection_pool=redis_pool)\n\n启动ipythonipython --profile=apple\n\n执行效果Python 3.7.3 (default, Mar 27 2019, 16:54:48)Type &#x27;copyright&#x27;, &#x27;credits&#x27; or &#x27;license&#x27; for more informationIPython 7.34.0 -- An enhanced Interactive Python. Type &#x27;?&#x27; for help.IPython profile: appleIn [1]: cr.execute(&quot;&quot;&quot;select id from res_users where login=%(login)s limit 1&quot;&quot;&quot;, &#123;&#x27;login&#x27;: &#x27;admin&#x27;&#125;)In [2]: cr.dictfetchone()Out[2]: &#123;&#x27;id&#x27;: 1&#125;In [3]: user_ids = pool.get(&#x27;res.users&#x27;).search(cr, uid, [(&#x27;login&#x27;, &#x27;=&#x27;, &#x27;admin&#x27;)])In [4]: user_idsOut[4]: [1]","categories":["Python"],"tags":["Python","iPython","Odoo","OE","OpenERP"]},{"title":"服务器配置 - Nginx+Gunicorn+Supervisor+Flask","url":"/Server-Configuration.html","content":"为服务器添加ssh公钥验证Git安装配置Redis安装配置Nginx安装配置配置Python虚拟环境Gunicorn安装配置Supervisor安装配置","categories":["服务器"],"tags":["Linux","服务器"]},{"title":"Python - Gunicorn安装配置","url":"/Server-Gunicorn-Configuration.html","content":"安装cd /var/www/happy # 进入项目代码目录source venv/bin/activate # 激活并进入虚拟环境pip install gunicorn # 在虚拟环境中安装gunicorn\n\n使用gunicorn启动Flask项目gunicorn -w4 -b127.0.0.1:8003 happy:app\n\n\n这里的happy是Flask项目的app名-w4 等同于 –workers&#x3D;4，意为同时启动四个worker-b127.0.0.1:8003 等同于 –bind&#x3D;127.0.0.1:8003，用于指定绑定的服务器ip和端口\n\n关闭进程\nCtrl+C即可。\n\n\n后台进程可以使用以下命令查看进程号(pid):\n\nps -ef | grep gunicorn\n\n\n关闭进程命令：\n\nkill [pid]\n\n\n\n推荐使用supervisor来管理gunicorn进程，优点是启动、停止、重启都很方便，并且支持自动重启被意外停止的进程，可以参考&gt;&gt;传送门 - Supervisor安装配置&lt;&lt;。\n\n","categories":["Python","Gunicorn"],"tags":["Python","Linux","服务器","Gunicorn"]},{"title":"服务器配置 - Nginx安装配置","url":"/Server-Nginx-Configuration.html","content":"安装apt-get install nginx\n\n增加代理配置cd /etc/nginx/sites-availablevim your_site_name\n\n\n普通http配置参考：\n\n# http serverserver &#123;       listen 80;       server_name your.site.name.cn;       # ssl on;       access_log /var/log/nginx/syour_site_name.access.log;       error_log /var/log/nginx/your_site_name.error.log;\tlocation / &#123;\t\tproxy_pass http://127.0.0.1:8011;\t\tproxy_set_header Host $host;                proxy_set_header X-Real-IP $remote_addr;\t\tproxy_set_header X-Forward_For $proxy_add_x_forwarded_for;\t&#125;\n\n\n安全https配置参考：\n\n# HTTPS serverserver &#123;        listen 443;        listen [::]:443 ipv6only=on;        server_name your.site.name.cn;        ssl on;        access_log /var/log/nginx/your_site_name.access.log;        error_log /var/log/nginx/your_site_name.error.log;        ssl_certificate /path/to/your/https/cert/your_site_name.pem;        ssl_certificate_key /path/to/your/https/cert/your_site_name.key;        ssl_session_timeout 5m;        location / &#123;                proxy_pass http://127.0.0.1:8012;                proxy_set_header Host $host;                proxy_set_header X-Real-IP $remote_addr;                proxy_set_header X-Forward_For $proxy_add_x_forwarded_for;        &#125;&#125;\n\n\n将文件链接至sites-enabled目录下。\n\nln -s /etc/nginx/sites-available/your_site_name /etc/nginx/sites-enabled/your_site_name\n\n\n*这是因为sites-available目录下存放的只是备选配置，sites-enabled目录下才是真正有效的代理设置。\n\nNginx配置vim /etc/nginx/nginx.conf\n\n\n修改下前几行内容:\n\nuser www-data;worker_processes 4; # worker数worker_rlimit_nofile 60000; pid /run/nginx.pid;events &#123;        worker_connections 65535; # 最大同时连接数        multi_accept on; # 开启接受同时连接选项&#125;\n\n重载配置/usr/sbin/nginx -s reload\n\n这一步做完Nginx已经可以正常工作了。\n\n常用命令启动/usr/sbin/nginx\n\n停止/usr/sbin/nginx -s stop\n\n验证配置文件是否正确/usr/sbin/nginx -t\n","categories":["Nginx"],"tags":["Linux","服务器","Nginx"]},{"title":"服务器配置 - Redis单机多实例配置","url":"/Server-Redis-Multi-Instance.html","content":"拷贝配置文件\n可以参考&gt;&gt;传送门 - Redis安装配置&lt;&lt;。Redis安装时会生成一份默认配置&#x2F;etc&#x2F;redis&#x2F;redis.conf，几个常用配置项如下：\n\nvim /etc/redis/redis.conf\n\n# 端口port 6379# pid文件路径pidfile /var/run/redis/redis-server.pid# 绑定ipbind 139.xxx.xxx.xxx 127.0.0.1# 登录需要密码requirepass 123456# log文件路径logfile /var/log/redis/redis-server.log# 持久化输出的数据库文件dbfilename dump.rdb# 只增文件的文件名称appendfilename &quot;appendonly.aof&quot;\n\n\n将配置文件拷贝一份，并修改下内容：\n\ncp /etc/redis/redis.conf /etc/redis/redis-2.confvim /etc/redis/redis-2.conf\n\n# 端口port 6789# pid文件路径pidfile /var/run/redis/redis-2.pid# 绑定ipbind 139.xxx.xxx.xxx 127.0.0.1# 登录需要密码requirepass 123456# log文件路径logfile /var/log/redis/redis-2.log# 持久化输出的数据库文件dbfilename dump-2.rdb# 只增文件的文件名称appendfilename &quot;appendonly-2.aof&quot;\n\n手动启动\n从不同的配置文件启动Redis实例\n\nredis-server  /etc/redis/redis.confredis-server  /etc/redis/redis-2.conf\n\n到这里两个实例都可以正常工作了。\n\n*3. 主从配置\n一些场景下需要配置Redis主从数据库，如读写分离。Redis的主从配置还是很容易的，只要修改下从库的配置文件的slaveof项即可。\n\nvim /etc/redis/redis-2.conf\n\n# 从属关系，如果是在同一台机器上可以把ip设置为127.0.0.1slaveof  139.xxx.xxx.xxx  6379\n\n*4. 设置开机启动\n默认情况下只有第一个实例会开机启动，其他的实例需要手动启动，下面将讲解如何让第二个实例也开机启动。\n\n先拷贝一份原来的启动脚本cp /etc/init.d/redis-server /etc/init.d/redis-server-2\n\n修改新的启动脚本vim /etc/init.d/redis-server-2\n\n\n前几行需要修改的内容如下：\n\nPATH=/usr/local/sbin:/usr/local/bin:/sbin:/bin:/usr/sbin:/usr/binDAEMON=/usr/bin/redis-serverDAEMON_ARGS=/etc/redis/redis-2.confNAME=redis-server-2DESC=redis-server-2RUNDIR=/var/run/redisPIDFILE=$RUNDIR/redis-server-2.pid\n\n\n\n*以后就可以使用下面的命令来启动&#x2F;停止新的实例了\n\n/etc/init.d/redis-server-2 start # 启动/etc/init.d/redis-server-2 stop # 停止\n\n将新脚本加入开机启动项\n方法一：使用update-rc.d命令，20是想要指定的启动序号。\n\nupdate-rc.d -f redis-server-2 defaults 20\n\n\n方法二：手动添加开机启动项，可以参考这篇文章&gt;&gt;传送门 - Linux设置开机启动项&lt;&lt;，两个方法的结果是相同的。\n\n\n配置完成，此时敲reboot重启机器就可以实现开机自动启动这两个实例了。\n\n*取消开机启动update-rc.d -f redis-server-2 remove\n","categories":["Redis"],"tags":["Linux","服务器","Redis"]},{"title":"服务器配置 - Redis安装配置","url":"/Server-Redis-Configuration.html","content":"安装apt-get install redis-server\n\n配置vim /etc/redis/redis.conf\n\n\n这里仅介绍几个基本配置\n\n# 端口port 6379# pid文件路径pidfile /var/run/redis/redis-server.pid# 绑定ipbind 139.xxx.xxx.xxx 127.0.0.1# 登录需要密码requirepass 123456# log文件路径logfile /var/log/redis/redis-server.log# 持久化输出的数据库文件dbfilename dump.rdb# 只增文件的文件名称appendfilename &quot;appendonly.aof&quot;\n\n重启/etc/init.d/redis-server restart\n这一步做完redis-server已经可以正常工作了。\n\n常用命令连接redis-cli -h 139.xxx.xxx.xxx -p 6379 -a 123456 \n\n\n如果是本地连接的话-h参数可以省略使用默认端口6379的话-p参数可以省略没有设置密码的话-a参数可以省略\n\n关闭redis-cli shutdown\n\n启动服务器redis-server\n\n\n\n在一台机器上配置多个Redis服务器可以参考&gt;&gt;传送门 - Redis单机多实例配置&lt;&lt;。\n\n","categories":["Redis"],"tags":["Linux","服务器","Redis"]},{"title":"服务器搭建 - 为服务器添加ssh公钥验证","url":"/Server-SSH-Key.html","content":"生成密钥对\n在本地运行如下命令：\n\nssh-keygen -t rsa -b 4096 -C &quot;your_email@example.com&quot;\n如果不想设置密码的话直接三次回车即可，和git生成密钥的命令相同。\n\n生成的密钥对位置在 ~&#x2F;.ssh，查看下公钥，下一步要用到。\n\ncat ~/.ssh/id_rsa.pub\n\n\n内容类似下面这样\n\nssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAACAQC+am2s/r1n+xsipi/4H2ll8p3McdhQCLBwJGNbkaxpeWKtdbiUbqAWeNt/OF13VsyWLs5lb6J2I3J6GlCcEGMGOFc4gzLTP9e/TmXeyFlBMZkuSJTbsXvL9Q/tff/8Tgt4aVAeOAgSd2jdDEvALegap4nrMHVLP8sOQlNFBMPjy1r0cW/Afp32gCtPOpQRuIkQdOnWUkzjObGanhYnX470UNsvgQ+IyikhS5tiKPqkT317v6yFV4doeZgfNYtcgpLVZcVxkItTLS1h75d4h4MD2JVRk2nBGSLp5j2WIji4Tiy++LblV1Y5Y2wRcfefdXCIMT3jMNAcyhuCaNfaD/Q== your_email@example.com\n\n添加到服务器ssh root@server_ip # 登陆服务器mkdir .ssh # 创建.ssh目录vim .ssh/authorized_keys # 创建已验证的密钥记录文件\n\n\n在vim编辑器中按i键，把上一步的公钥拷贝进来，多个公钥的话换行隔开即可。然后按ESC键退出编辑模式，输入:wq回车即可保存文件。这样以后输入ssh root@ip命令就可以不用输入密码直接进去了。\n\n\n\n更快捷地登陆完成上面的配置后，还可以通过对本地ssh进行配置以进一步简化登陆操作。\n\n在本地打开~&#x2F;.ssh&#x2F;config 文件\n\nvim ~/.ssh/config\n\n\n添加如下配置内容:\n\nHost happyHostname 139.xxx.xxx.xxxUser rootIdentityFile ~/.ssh/id_rsa\n\n以后在本地直接输入以下命令就可登陆远程服务器\n\nssh happy\n\n\n多个服务器配置只需换行隔开即可。\n\n","categories":["服务器","SSH"],"tags":["Linux","ssh"]},{"title":"Hello World","url":"/hello-world.html","content":"[200]博客访问地址 - Github[404]博客访问地址 - Coding[404]博客访问地址 - Gitee"},{"title":"Python - Supervisor安装配置","url":"/Server-Supervisor-Configuration.html","content":"安装pip install supervisor\n\n初始化启动配置文件echo_supervisord_conf &gt; /etc/supervisord.confvim /etc/supervisord.conf\n\n\n最后面加上下面这两行内容，这样就可以从&#x2F;etc&#x2F;supervisor目录下自动加载所有的conf文件了。\n\n[include]files = /etc/supervisor/*.conf\n\n新建项目配置文件mkdir /var/log/supervisormkdir /etc/supervisorvim /etc/supervisor/happydev.conf\n\n\n内容如下：\n\n[program:happydev]directory = /var/www/happydev ;command = /var/www/happydev/venv/bin/gunicorn -w4 -b127.0.0.1:8003 --timeout 120  happy:app ;autostart = true ;startsecs = 5 ;autorestart = true ;startretries = 3 ;user = root ;redirect_stderr = true ;stdout_logfile_maxbytes = 100MB ;stdout_logfile_backups = 10 ;stdout_logfile = /var/log/supervisor/happydev.log ;environment = HAPPY_CONFIG_FILE=&quot;/var/www/happydev/happy/config/staging.py&quot;,HAPPY_PATH=&quot;/var/www/happydev&quot; ;\n\n\n这里管理的进程是使用gunicorn启动的Flask项目，关于gunicorn的使用可以参考&gt;&gt;传送门 - Gunicorn安装配置&lt;&lt;。\n\n启动suprervisordsupervisord -c /etc/supervisord.conf\n\n\n到这一步supervisor已经正常工作了。\n\n\n常用命令停止supervisor主进程\n查看supervisord进程号(pid)：\n\nps aux | grep supervisord\n\n\n关闭进程：\n\nkill [pid]\n\n启动单个项目进程supervisorctl start happydev\n\n停止单个项目进程supervisorctl stop happydev\n\n\n注意：使用此命令停止的进程不会被自动重启机制重新启动\n\n重启单个项目进程supervisorctl restart happydev\n\n重新加载单个项目supervisorctl remove happydev # 移除happydev项目supervisorctl reread # 重新读取所有配置文件supervisorctl add happydev # 添加happydev项目\n\n查看所有项目进程的运行状态supervisorctl status\n","categories":["Supervisor"],"tags":["Python","Linux","服务器","Supervisor"]}]